import asyncio

import discord
from discord import app_commands, Interaction
from discord.ext import commands
from dotenv import dotenv_values
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_mongodb import MongoDBAtlasVectorSearch
from langchain_voyageai import VoyageAIEmbeddings
from pymongo import MongoClient

import utils.Logs as logs
import utils.Utility as util
from main import MynaBot

prompt_template = """
ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì‹¤ì— ì…ê°í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì§ˆë¬¸:
{question}

ê´€ë ¨ ë¬¸ì„œ:
{context}

ë‹µë³€:
"""

class Edac(commands.Cog):
    def __init__(self, bot: MynaBot):
        print(f'{type(self).__name__}ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.')
        self.bot = bot

    def get_retriever(self):
        denv = dotenv_values(".env")
        print("--- ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ---")
        client = MongoClient(denv["MONGODB_URL"])
        db_name = "rag"
        collection_name = "edac-rag"
        collection = client[db_name][collection_name]

        embedding_model = VoyageAIEmbeddings(model="voyage-3.5")

        vectorstore = MongoDBAtlasVectorSearch(
            collection=collection,
            embedding=embedding_model,
            index_name="default"
        )

        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
        return retriever

    def get_rag_chain(self):
        retriever = self.get_retriever()
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.5)
        rag_prompt = PromptTemplate.from_template(prompt_template)

        # ì²´ì¸ êµ¬ì„±: {input -> retriever -> docs -> context formatting -> prompt -> llm -> output}
        chain = (
                {"context": retriever | (lambda docs: "\n\n".join([doc.page_content for doc in docs])),
                 "question": RunnablePassthrough()}
                | rag_prompt
                | llm
                | StrOutputParser()
        )

        return chain, retriever

    def sync_get_answer_from_rag(self, query):
        chain, retriever = self.get_rag_chain()
        answer = chain.invoke(query) # ë‹µë³€
        source_docs = retriever.invoke(query) # ì¶œì²˜
        return answer, source_docs

    # ë¹„ë™ê¸° ë˜í•‘ í•¨ìˆ˜
    async def get_answer_from_rag_async(self, query):
        return await asyncio.to_thread(self.sync_get_answer_from_rag, query)

    def split_message(self, text:str, max_length=2000):
        """ë¬¸ìì—´ì„ ë””ìŠ¤ì½”ë“œ ë©”ì‹œì§€ ê¸¸ì´ì— ë§ê²Œ ë¶„í• """
        lines = text.split('\n')
        chunks = []
        current = ""
        for line in lines:
            if len(current) + len(line) + 1 > max_length:
                chunks.append(current)
                current = line
            else:
                current += "\n" + line if current else line
        if current:
            chunks.append(current)
        return chunks

    @app_commands.command(description='AI + RAG ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì¹´í˜ì— ìˆëŠ” ì›í•˜ëŠ” ê°•ì˜ê¸€ì„ ë² ì´ìŠ¤ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.')
    @app_commands.describe(message="ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•©ë‹ˆë‹¤.")
    async def ì§ˆë¬¸í•˜ê¸°(self, interaction: Interaction[MynaBot], message: str):
        await interaction.response.defer()

        await logs.send_log(bot=self.bot,
                            log_text=f"{interaction.guild.name}ì˜ {interaction.user.display_name}ë‹˜ì´ ê°•ì˜ ê²€ìƒ‰ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤.")
        
        try:
            answer, sources = await self.get_answer_from_rag_async(message)

            if sources:
                source_text = f"\n\n## Reference\n"
                for i, doc in enumerate(sources):
                    meta = doc.metadata
                    title = meta.get("title", "No title")
                    author = meta.get("author_nickname", "No Author")
                    source_url = meta.get("source", "No link")

                    source_text += f"-# {i+1}ë²ˆ. {title} ({author}ë‹˜) [ë§í¬]({source_url})\n"

                answer += source_text

            answer_chunks = self.split_message(f"ğŸ§  **ë§ˆì´ë‚˜ì˜ ë‹µë³€:**\n\n{answer}")
            for chunk in answer_chunks:
                await interaction.followup.send(chunk)

        except Exception as e:
            print(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ! {e}")

async def setup(bot):
    await bot.add_cog(Edac(bot))
